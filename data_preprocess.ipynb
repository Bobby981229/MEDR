{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Shangyuan Liu\n",
    "\n",
    "Username: acp21sl\n",
    "\n",
    "UCard: 001768913\n",
    "\n",
    "Module: COM6013 - Cybersecurity and Artificial Intelligence Dissertation Project\n",
    "\n",
    "Project Name: Malicious Endpoint Detection and Response\n",
    "\n",
    "Step 01: Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../Dataset/IoT-DS2.csv\"  # the original dataset\n",
    "dataset = pd.read_csv(data_path)  # read the raw dataset into data-frame\n",
    "\n",
    "df_raw = dataset.copy()\n",
    "df_raw = df_raw.drop('Bwd_IAT_Mean.1', axis=1)  # remove the last column - all NAN\n",
    "\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对Dataframe进行统计分析, 查看正常数据与异常数据的比例\n",
    "\n",
    "统计攻击类型和对应的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The number of rows in raw dataset', df_raw.shape[0])  # rows  -- 1438157\n",
    "print('The number of columns in raw dataset', df_raw.shape[1])  # columns  --  86\n",
    "\n",
    "label_statistics = df_raw[\"Label\"].value_counts()  # the statistics of Label features\n",
    "cat_statistics = df_raw[\"Cat\"].value_counts()  # the statistics of Cat features\n",
    "\n",
    "print('\\nThe statistics of Label feature \\n', label_statistics)\n",
    "print('\\nThe statistics of Cat feature \\n', cat_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "清理无穷大和无穷小的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delInf = df_raw.replace([np.inf, -np.inf], np.nan).dropna() # replace and delete all inf and -inf values to NaN\n",
    "df_delInf   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repZero = df_delInf.replace(0, np.nan)   # replace all 0 values to NaN\n",
    "\n",
    "def missing_rate(df):\n",
    "    \"\"\"\n",
    "    calculate the rate of missing values (NaN) in each feature\n",
    "    Args:\n",
    "        df (_data-frame_): df_raw\n",
    "    Returns:\n",
    "        _float_: percentage of missing values in each feature data\n",
    "    \"\"\"\n",
    "    # statistics on the number and percentage of missing values\n",
    "    nan_percent = (df.isnull().sum() / len(df)) * 100\n",
    "    # Get the percentage of missing values in each column, sorted in ascending order\n",
    "    # >0 is to screen out columns without missing values and return only those with missing values\n",
    "    nan_percent = nan_percent[nan_percent > 0].sort_values()\n",
    "    return nan_percent\n",
    "\n",
    "missingVal_feature = missing_rate(df_repZero)\n",
    "\n",
    "# print the rate of NaN value\n",
    "print(\"The percentage of each feature's missing value\\n\", missingVal_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a threshold value to remove any features with a percentage of missing value above the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 90 \n",
    "# the percentage of missing value over 90%\n",
    "missingVal_90 = missingVal_feature[missingVal_feature > threshold]\n",
    "\n",
    "# set a list to store any features should be removed\n",
    "delete_list = missingVal_90.index.tolist()\n",
    "\n",
    "# features in delete_list are deleted to create a new data-frame\n",
    "df_delMissVal = df_delInf.drop(delete_list, axis=1)\n",
    "\n",
    "df_delMissVal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all meaningless features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove all meaningless features\n",
    "# df_dropFeats = df_delMissVal.drop([\"Flow_ID\", \"Src_IP\", \"Src_Port\", \"Dst_IP\", \"Dst_Port\", \"Protocol\", \"Timestamp\"], axis=1)\n",
    "# df_dropFeats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delMissVal['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delMissVal['Label'].value_counts().index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 8)) \n",
    "\n",
    "labels = df_delMissVal['Label'].value_counts().index.to_list()\n",
    "data = df_delMissVal['Label'].value_counts().to_list()\n",
    "plt.bar(labels, data, color=['salmon','turquoise'])\n",
    "plt.title('Number of normal and anomaly data in dataset')\n",
    "\n",
    "for a, b in zip(labels, data):\n",
    "    plt.text(a, b, '%.0f' % b, ha='center', va='bottom', font='TIMES NEW ROME', fontsize=11)\n",
    "\n",
    "# Solve the problem of unclear and incomplete pictures\n",
    "plt.savefig(\"../images/labels_batChart.png\", dpi=500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 9))  # adjusting the size of graphics\n",
    "\n",
    "data = df_delMissVal['Label'].value_counts()  # the number of each label\n",
    "\n",
    "plt.pie(data,\n",
    "        labels=df_delMissVal['Label'].value_counts().index, # set pie chart labels\n",
    "        colors=[\"#d5695d\", \"#5d8ca8\"], # set colours\n",
    "        explode=(0, 0.2),  # \n",
    "        autopct='%.2f%%',  # formatted output percentages\n",
    "       )\n",
    "plt.title(\"Distribution of normal and anomaly data in dataset\")\n",
    "plt.legend()\n",
    "\n",
    "# Solve the problem of unclear and incomplete pictures\n",
    "plt.savefig(\"../images/labels_pieChart.png\",dpi=500, bbox_inches = 'tight') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delMissVal['Cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22, 10))\n",
    "\n",
    "categories = df_delMissVal['Cat'].value_counts().index\n",
    "y_pos = np.arange(len(categories)) \n",
    "amount = df_delMissVal['Cat'].value_counts()\n",
    "plt.barh(y_pos, amount, align='center', color='skyblue')\n",
    "plt.yticks(y_pos, categories)\n",
    "plt.title('Distribution of different types of categories in the dataset')\n",
    "plt.xlabel('Number of occurences')\n",
    "plt.ylabel('Categories')\n",
    "for i, v in enumerate(amount):\n",
    "    plt.text(v + 5, i - 0.3 , str(v))\n",
    "\n",
    "# Solve the problem of unclear and incomplete pictures\n",
    "plt.savefig(\"../images/cat_barChart.png\", dpi=500, bbox_inches = 'tight')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "映射 特征转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting text data to numeric type data\n",
    "df_convert = df_delMissVal.replace(['Normal', 'Anomaly'], [0, 1]).replace(\n",
    "    ['Normal', 'DDoS', 'PortScan', 'Okiru', 'Reconnaissance', 'Mirai', 'Sparta', 'MQQT_bruteforce', 'Torii', 'C&C', 'DoS', 'Attack', 'Flood', 'HeartBeat', 'MITM ARP Spoofing', 'FileDownload', 'Theft'], \n",
    "    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16])\n",
    "\n",
    "df_convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算相关系数 Pearson correlation coefficient - PCC \n",
    "# 相关系数可视化 - 热力图 heatmap\n",
    "# get all features data-frame\n",
    "df_feature = df_convert.iloc[:, : -2]\n",
    "df_pcc = df_feature.corr('pearson')  # calculate pearson correlation coefficient\n",
    "\n",
    "plt.subplots(figsize=(len(df_pcc), len(df_pcc)))\n",
    "sns.heatmap(df_pcc, annot=True, vmax=1, square=True, cmap=\"Blues\")\n",
    "plt.savefig(\"../images/feature_pcc.png\",dpi=500,bbox_inches = 'tight')  # Solve the problem of unclear and incomplete pictures\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Save the dataframe as a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_convert.to_csv(\"../Dataset/dataset_cleaned.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e891a50acc2c8898cf76d460cc39b14e07cac2dad21b054de3e4a2591c86fc8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
