{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../Dataset/dataset_cleaned.csv\"  # the original dataset\n",
    "df_raw = pd.read_csv(data_path)  # read the raw dataset into dataframe\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.utils.shuffle(df_raw)  # shuffle df order\n",
    "X, y = df_raw.iloc[:, :-2], df_raw.iloc[:, -2]  # split feature, target arrays\n",
    "\n",
    "# split dataset: training set-80% testing set-20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all meaningless features and copy a testing dataset sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy a dataset sample\n",
    "X_test_raw = X_test.copy()\n",
    "\n",
    "# remove all meaningless features\n",
    "X_train = X_train.drop([\"Flow_ID\", \"Src_IP\", \"Src_Port\", \"Dst_IP\", \"Dst_Port\", \"Protocol\", \"Timestamp\"], axis=1)\n",
    "\n",
    "X_test = X_test.drop([\"Flow_ID\", \"Src_IP\", \"Src_Port\", \"Dst_IP\", \"Dst_Port\", \"Protocol\", \"Timestamp\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests Method - Gini Index 二分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_model(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Build a random forests model\n",
    "    Args:\n",
    "        X_train (_type_): training dataset - input features\n",
    "        X_test (_type_): testing dateset - input feature\n",
    "        y_train (_type_): training dataset - output label\n",
    "        y_test (_type_): testing dateset - output label\n",
    "    \"\"\"\n",
    "    # build the RF model\n",
    "    classifier = RandomForestClassifier(random_state=2022, n_estimators=50, criterion='entropy')\n",
    "    # training model\n",
    "    rf = classifier.fit(X_train, y_train)\n",
    "    # predict test dataset\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print(f\"Training Score: {classifier.score(X_train, y_train)}\") \n",
    "    print(f\"Test Score: {classifier.score(X_test, y_test)}\")\n",
    "    return rf, y_pred\n",
    "    \n",
    "    \n",
    "def model_evaluate(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Evaluate the model using predicted labels\n",
    "    Args:\n",
    "        y_test (_type_): testing dateset - output label\n",
    "        y_pred (_type_): predicted labels\n",
    "    \"\"\"\n",
    "    # report classification results for each category\n",
    "    eval_result1 = classification_report(y_test, y_pred)\n",
    "    print(\"Classification Report: \\n\", eval_result1)\n",
    "\n",
    "    eval_result2 = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", eval_result2)\n",
    "    return eval_result1, eval_result2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train and evaluate RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9998435490039287\n",
      "Test Score: 0.9952438897194312\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99     45218\n",
      "           1       1.00      1.00      1.00    242412\n",
      "\n",
      "    accuracy                           1.00    287630\n",
      "   macro avg       0.99      1.00      0.99    287630\n",
      "weighted avg       1.00      1.00      1.00    287630\n",
      "\n",
      "Accuracy: 0.9952438897194312\n"
     ]
    }
   ],
   "source": [
    "rf, y_pred = RF_model(X_train, X_test, y_train, y_test)  # training model\n",
    "eval_result1, eval_result2 = model_evaluate(y_test, y_pred)  # evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the importance of each feature and sort in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) Fwd_Seg_Size_Min               0.119865\n",
      " 2) Fwd_IAT_Min                    0.089994\n",
      " 3) SYN_Flag_Cnt                   0.086617\n",
      " 4) Idle_Mean                      0.082633\n",
      " 5) Init_Fwd_Win_Byts              0.071761\n",
      " 6) Idle_Min                       0.068613\n",
      " 7) Flow_IAT_Min                   0.065730\n",
      " 8) Fwd_Header_Len                 0.057831\n",
      " 9) Idle_Max                       0.043891\n",
      "10) Bwd_Header_Len                 0.028092\n",
      "11) Flow_IAT_Std                   0.026841\n",
      "12) Fwd_IAT_Tot                    0.022645\n",
      "13) Fwd_IAT_Std                    0.022121\n",
      "14) Tot_Fwd_Pkts                   0.020295\n",
      "15) Flow_IAT_Max                   0.020100\n",
      "16) Flow_IAT_Mean                  0.019342\n",
      "17) Bwd_Pkts/s                     0.015876\n",
      "18) Tot_Bwd_Pkts                   0.015120\n",
      "19) Fwd_IAT_Mean                   0.013964\n",
      "20) Subflow_Bwd_Pkts               0.013756\n",
      "21) Fwd_IAT_Max                    0.012864\n",
      "22) Fwd_Pkts/s                     0.010213\n",
      "23) Bwd_Seg_Size_Avg               0.009609\n",
      "24) Pkt_Len_Max                    0.009239\n",
      "25) Flow_Byts/s                    0.008883\n",
      "26) Flow_Pkts/s                    0.008046\n",
      "27) TotLen_Fwd_Pkts                0.007849\n",
      "28) Init_Bwd_Win_Byts              0.006181\n",
      "29) Idle_Std                       0.004990\n",
      "30) Flow_Duration                  0.003955\n",
      "31) Subflow_Fwd_Pkts               0.001681\n",
      "32) Pkt_Len_Min                    0.001565\n",
      "33) ACK_Flag_Cnt                   0.001427\n",
      "34) Fwd_Pkt_Len_Min                0.000898\n",
      "35) Pkt_Size_Avg                   0.000890\n",
      "36) TotLen_Bwd_Pkts                0.000883\n",
      "37) Subflow_Fwd_Byts               0.000665\n",
      "38) Fwd_Pkt_Len_Max                0.000615\n",
      "39) Pkt_Len_Mean                   0.000545\n",
      "40) Fwd_Seg_Size_Avg               0.000522\n",
      "41) Fwd_Pkt_Len_Mean               0.000441\n",
      "42) Bwd_IAT_Max                    0.000425\n",
      "43) Subflow_Bwd_Byts               0.000382\n",
      "44) Bwd_Pkt_Len_Mean               0.000345\n",
      "45) Bwd_Pkt_Len_Max                0.000265\n",
      "46) PSH_Flag_Cnt                   0.000220\n",
      "47) Down/Up_Ratio                  0.000204\n",
      "48) Bwd_IAT_Mean                   0.000178\n",
      "49) Fwd_Act_Data_Pkts              0.000178\n",
      "50) Bwd_IAT_Tot                    0.000173\n",
      "51) Bwd_IAT_Std                    0.000136\n",
      "52) Pkt_Len_Var                    0.000114\n",
      "53) Pkt_Len_Std                    0.000105\n",
      "54) Fwd_Pkt_Len_Std                0.000069\n",
      "55) Bwd_IAT_Min                    0.000065\n",
      "56) Bwd_Pkt_Len_Min                0.000051\n",
      "57) Bwd_Pkt_Len_Std                0.000037\n",
      "58) Active_Min                     0.000008\n",
      "59) Active_Mean                    0.000001\n",
      "60) Active_Max                     0.000000\n"
     ]
    }
   ],
   "source": [
    "feat_labels = X_train.columns  # get all the features names - 60\n",
    "\n",
    "feature_drop = []  # store the features need to be deleted\n",
    "\n",
    "importances = rf.feature_importances_  # get feature importances from random forests model\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, feat_labels[indices[f]], importances[indices[f]]))\n",
    "    if importances[indices[f]] < 0.001:\n",
    "        feature_drop.append(feat_labels[indices[f]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features\n",
    "X_train = X_train.drop(feature_drop, axis=1)\n",
    "X_test = X_test.drop(feature_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save testing dataset after features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.concat([X_test, y_test], axis=1)  # concat data features and labels\n",
    "df_test.to_csv(\"../Dataset/binary/dataset_test.csv\", index = False)\n",
    "\n",
    "X_test_raw.to_csv(\"../Dataset/binary/dataset_test_raw.csv\", index = False) # the raw testing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model - Binary 时间成本低，性能增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranining a model after features selection\n",
    "rf, y_pred = RF_model(X_train, X_test, y_train, y_test)  # training model\n",
    "eval_result1, eval_result2 = model_evaluate(y_test, y_pred)  # evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STOME - Data Oversampling 针对训练集进行数据采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = X_train\n",
    "data_y = y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE for Imbalanced Classification - Synthetic Minority Over-sampling Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOTE = SMOTE()\n",
    "X__SMOTE, y__SMOT = SMOTE.fit_resample(data_x, data_y)  # fit and transform\n",
    "\n",
    "df_concat = pd.concat([X__SMOTE, y__SMOT], axis=1)  # concat data features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build feature, target arrays \n",
    "X, y = df_concat.iloc[:, :-1], df_concat.iloc[:, -1]\n",
    "\n",
    "# Train/test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=2022) \n",
    "\n",
    "rf, y_pred = RF_model(X_train, X_test, y_train, y_test)  # training model\n",
    "eval_result1, eval_result2 = model_evaluate(y_test, y_pred)  # evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the new binary dataset\n",
    "# df_concat.to_csv(\"../Dataset/binary/dataset_train.csv\", index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTETomek sampling for imbalanced classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_tomek = SMOTETomek()\n",
    "X_resampled, y_resampled = smote_tomek.fit_resample(data_x, data_y) # fit and transform\n",
    "\n",
    "sorted(Counter(y_resampled).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat_2 = pd.concat([X_resampled, y_resampled], axis=1)  # concat data features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build feature, target arrays \n",
    "X, y = df_concat_2.iloc[:, :-1], df_concat_2.iloc[:, -1]\n",
    "\n",
    "# Train/test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=2022) \n",
    "\n",
    "rf, y_pred = RF_model(X_train, X_test, y_train, y_test)  # training model\n",
    "eval_result1, eval_result2 = model_evaluate(y_test, y_pred)  # evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the new binary dataset\n",
    "df_concat_2.to_csv(\"../Dataset/binary/dataset_train.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e891a50acc2c8898cf76d460cc39b14e07cac2dad21b054de3e4a2591c86fc8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
